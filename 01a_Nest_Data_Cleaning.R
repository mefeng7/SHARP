#Data tidying
library(tidyverse)
library(lubridate)
library(stringi)
#spatial analysis
library(sf)
library(sp)
library(terra)
library(tmap)
# spatial datasets
library(spData)
library(geodata)
library(rnaturalearth)


## Set file path to data
# -------------------------------------------
dat_path<-"G:/My Drive/Research/SHARP/Data/"



## Load data
# -------------------------------------------

# 1. Nest fates - select nest ID and nest fate - look up unique values, could subset by known causes of failure
fates<-read.csv(paste0(dat_path,"NestFates_2001-2020.csv"),na.strings=c("","NOT REC","NA"))%>%
  dplyr::select("id"="SHARPNestID","fate"="UltimateNestFate")%>%
  mutate(missing.location.rec=0,
         missing.site.info=0,
         missing.coords=0,
         coord.typo=0,
         batch_DecMin_DD_reversed=0,
         batch_DecMin_DD=0,
         batch_dec_addition=0,
         batch_dec_addition_reversed=0,
         batch_move_DD_to_LatLong=0)
#adjusted id id19051 to ID19051

#Nest location information - select nest ID, Site code, Year, Species, Coordinate information
nests<-read.csv(paste0(dat_path,"Nests_2001-2020.csv"),na.strings=c("","NOT REC","NA"))%>%
  dplyr::select("id"="SHARPNestID","site.code"="Site", "Year", "Species",
                "coord.system"="Coordinate.System", "utm.zone"="UTM.Zone", "Easting", "Northing", "Lat", "Long")%>%
  #Remove records missing site and year info (these were added as filler data to merge with veg data)
  filter(!is.na(site.code)&!is.na(Year))
#adjusted SAlS to SALS for 1 id



# 2. Site information - select Site code, site name, and state
sites_sop<-read.csv(paste0(dat_path,"Sites.csv"),na.strings=c("","NOT REC","NA"))%>%
  dplyr::select("site.code"="Site_Code","Site", "State")

sites_kate<-read.csv(paste0(dat_path,"Nest_Site_Metadata_kate.csv"),na.strings=c("","NOT REC","NA"))%>%
  dplyr::select("site.code"="SiteID", "State","Region")

  #additional site info from Sam's code
  sites_sam<- data.frame(site.code = c("AT", "BI", "CF", "CL", "DI", "EL", "ER", "HM", "FB", "FS", 
                                    "ID", "JC", "JO", "LU", "MN", "MQ", "MW", "Morris Island", "NC", "NO", 
                                    "OC", "PA", "PB", "PR", "SA", "SC", "SG", "SY", "WI", "NC2", 
                                    "MM", "SP", "FS1", "WA", "MIRI", "STJN", "WOBE"),
                      State = c("NJ", "CT", "MA", "NH", "ME", "ME", "CT", "CT", "ME", "NY",
                                "NY", "RI", "ME", "NH", "NY", "ME", "NJ", "NJ", "NY", "ME", 
                                "NJ", "XX", "ME", "MA", "NY", "ME", "VA", "ME", "VA", "NY", 
                                "ME", "RI", "NY", "CT", "DE", "DE", "DE"),
                      utm.zone = c("18T", "19T", "19T", "19T", "19T", "19T", "18T", "18T", "19T", "18T", 
                                  "18T", "19T", "19T", "19T", "18T", "19T", "18T", "18T", "18T", "19T", 
                                  "18T", NA, "19T", "19T", "18T", "19T", "18T", "19T", "18T", "19T", 
                                  "19T", "19T", "18T", "19T", "18T", "18T", "18T"))
  
sites<-full_join(sites_sop,sites_sam,by=c("site.code","State"))%>%
  full_join(sites_kate,by=c("site.code","State"))%>%
  distinct(site.code,.keep_all = T)

  # get UTM zones reported for each site
  #Greater than 72 D Long is zone 18, less than is zone 19
sites <- sites%>%
  mutate(utm.zone=case_when(
    # RI, MA, NH, ME are all within UTM zone 19
    is.na(utm.zone) & State %in% c("RI","MA","NH","ME") ~ "19T",
    # CT is split between 18 and 19, mostly 18 though (greater than 72 DD long is zone 18)
    # NY, NJ,VA, MD, DE are in zone 18
    is.na(utm.zone) & State %in% c("NY","NJ","VA","MD","DE") ~ "18T",
    !(is.na(utm.zone)) ~ utm.zone
  ))





## Address missing records between nest locations, fates, and sites data
# -------------------------------------------

# Not all nest location records have nest fate records
missing_fates<-nests%>%
  filter(!(id%in%fates$id))
nrow(missing_fates)
write.csv(missing_fates,paste0(dat_path,"nests_missing_fatedata.csv"), row.names = F)

# 44 nest fates are missing location data
missing_locations<-fates%>%
  filter(!(id%in%nests$id))
nrow(missing_locations)
fates[fates$id%in%missing_locations$id,]$missing.location.rec<-1
# this removes 38 fate records from site WB and 5 records with NA site codes
#fates<-fates%>%
#  filter(id%in%nests$id)



# Site codes missing site location information - see if SHARP folks know where these are
missing_states<- nests%>%
  filter(!(site.code%in%sites$site.code))%>%
  distinct(site.code,.keep_all = T)
fates[fates$id%in%missing_states$id,]$missing.site.info<-1

# Can some site names be merged?
site_list<-data.frame(site.code=sort(unique(nests$site.code)))%>%left_join(sites,by="site.code")


#write.csv(site_list, paste0(dat_path,"nest_site_list.csv"),row.names = F)



## merge nest fates and locations
# -------------------------------------------
dat1<-left_join(fates,nests,by="id")

# Fix site name discrepancies
# merge AT and ATT, BI and Barn Island, HM and Hammo, OC and Oyster creek - doesn't seem to be an issue in this dataset
unique(dat1$site.code)
# WA site is actually BI change the one record
dat1<-dat1%>%
  mutate(site.code = ifelse(
    substr(site.code, start=1,stop=2)=="WA","BI",site.code),
    id = ifelse(
      substr(id, start=1,stop=2)=="WA",gsub("WA","BI",id),id)
  )
  




## Spatial formatting
# -------------------------------------------

## A) Identify nest locations missing coordinates

# For Nests with location data
      # only keep records with a full set of UTM or lat long coordinate pairs
dat2<-filter(dat1,(if_all(c(Easting,Northing), ~ !is.na(.))|if_all(c(Lat,Long), ~ !is.na(.))))%>%
      # also remove coordinates that are 0 or small values (less than 30, likely typos)
      filter(if_any(c(Easting,Northing,Lat,Long), ~ .>30))

# Nests missing coordinates (402)
#missing_coords<-dat1%>%
#  filter(!(id%in%dat2$id))

#Mark records as missing coordinates only if they have location records.
dat1[!(dat1$id%in%dat2$id),]$missing.coords<-1
dat1[dat1$missing.location.rec==1,]$missing.coords<-0

nrow(dat1[dat1$missing.coords==1,])


## B) Assign coordinates to the correct coordinate system (batch conversions)

# range of longitude (E-W) for eastern coastline should be -67(Maine) to -79 (Virginia) DD
# range of latitude (N-S) should be 45 (Maine) to 36 (Virginia) DD 
# DD outside this range are likely typos

#B-1) Batch conversion of Degrees Decimal Minutes records (ONLY the case for NJ sites AT, OC, and MW in 2014 and 2015)

dat3<-dat1%>%
  # For records with coordinate information...
  filter(missing.coords!=1 & missing.location.rec!=1 & 
             # and sites AT, OC, or MW in 2014...
             (site.code %in% c("AT","OC","MW") & Year==2014))%>%
         #convert to DDs
  mutate(Long=as.numeric(substr(Easting,1,2))+(as.numeric(paste0(substr(Easting,3,4),".",substr(Easting,5,length(Easting))))/60),
         Lat=as.numeric(substr(Northing,1,2))+(as.numeric(paste0(substr(Northing,3,4),".",substr(Northing,5,length(Northing))))/60),
         #then remove the original values from the UTM coordinate columns
         Easting=NA,
         Northing=NA,
         #mark which edits were made
         batch_DecMin_DD=1)

dat1<-rbind(dat3,dat1[!(dat1$id%in%dat3$id),])

#2014 plotting shifted NE after conversion, slight systematic error remaining
#look at Sam's original data files
NJ14<-read.csv(paste0(dat_path,"Nest Locations/SESP 2011-2015.csv"))%>%
  dplyr::select(id=ID,Lat2=LAT,Long2=LONG,Year=YEAR)
NJ14<-read.csv(paste0(dat_path,"Nest Locations/SALS 2011-2015.csv"))%>%
  dplyr::select(id=ident,Lat2=Latitude,Long2=Longitude,Year)%>%
  rbind(NJ14)%>%
  mutate(yr=substr(Year,3,4),
         nest=substr(id,3,(nchar(id)-4)),
         sp=substr(id,(nchar(id)-3),nchar(id)),
         site=substr(id,1,2),
         id=paste0(site,yr,sp,nest))

NJ_test<-left_join(NJ14[NJ14$yr==14,c("id","Lat2","Long2")],dat2[,c("id","Easting","Northing")],by="id")%>%
  left_join(dat1[,c("id","Lat","Long")],by="id")%>%
  mutate(dif_lat=Lat2-Lat,
         dif_long=abs(Long2)-Long)
#take the average difference between original data points and database points.
diff_lat<-mean(NJ_test$dif_lat)
diff_long<-mean(NJ_test$dif_long)

# Sam's data are about 0.001 degrees off from ours and are plotting correctly.

# replace all the NJ 2014 data with Sam's SALS and SESP coordinates. 
NJ14<-NJ14%>%filter(yr=='14')
dat1<- dat1%>%
  left_join(NJ14[,c("id","Lat2","Long2")],by="id")%>%
  mutate(Lat = ifelse(id%in%NJ14$id, Lat2, Lat),
         Long = ifelse(id%in%NJ14$id, Long2, Long),
         #mark which edit was made
         replace_dat= ifelse(id%in%NJ14$id, 1, 0))%>%
  dplyr::select(-c("Lat2","Long2","batch_DecMin_DD"))

#For NJ 2014 non-SESP and SALS nests, apply the average difference to those coordinates
dat1<-dat1%>%
  mutate(Lat2 = ifelse(site.code %in% c("AT","OC","MW") & Year==2014 & !(Species%in%c("SESP","SALS")), Lat, NA),
         Long2 = ifelse(site.code %in% c("AT","OC","MW") & Year==2014 & !(Species%in%c("SESP","SALS")), Long, NA),
         Lat = ifelse(site.code %in% c("AT","OC","MW") & Year==2014 & !(Species%in%c("SESP","SALS")), Lat+diff_lat, Lat),
         Long = ifelse(site.code %in% c("AT","OC","MW") & Year==2014 & !(Species%in%c("SESP","SALS")), Long+diff_long, Long),
         coord_shift= ifelse(site.code %in% c("AT","OC","MW") & Year==2014 & !(Species%in%c("SESP","SALS")), 1, 0))
  

#Converting DMS to DD
#dat3<-dat2%>%
#  filter(Easting>6700000)%>%
#  mutate(Long=paste0(substr(Easting,1,2),"d",
#                            substr(Easting,3,4),"m",
#                            substr(Easting,5,6),"s",
#                            "W"),
#         Long=(as.numeric(char2dms(Long, chd='d', chm='m', chs='s'))),
#         Lat=paste0(substr(Northing,1,2),"d",
#                     substr(Northing,3,4),"m",
#                     substr(Northing,5,6),"s",
#                     "N"),
#         Lat=as.numeric(char2dms(Lat, chd='d', chm='m', chs='s')))%>%
#  rbind(dat2[!(dat2$Easting>6700000)|is.na(dat2$Easting),])



    # repeat DD conversion for records with lat/long reversed: At, OC, and MW in 2015
dat4<-dat1%>%
    # For records with coordinate information...
    filter(missing.coords!=1 & missing.location.rec!=1 & 
             # and sites AT,OC,MW in 2015...
             (site.code %in% c("AT","OC","MW") & Year==2015))%>%
  mutate(Long=as.numeric(substr(Northing,1,2))+(as.numeric(paste0(substr(Northing,3,4),".",substr(Northing,5,length(Northing))))/60),
         Lat=as.numeric(substr(Easting,1,2))+(as.numeric(paste0(substr(Easting,3,4),".",substr(Easting,5,length(Easting))))/60),
         #then remove the unconverted values from the UTM coordinate columns
         Easting=NA,
         Northing=NA,
         #mark which edits were made
         batch_DecMin_DD_reversed=1)
dat1<-rbind(dat4,dat1[!(dat1$id%in%dat4$id),])


# B-2) Batch conversion of UTM coords that are actually DD missing decimals (Checked plotting as original UTMs and converting dMin to DD, neither worked) 
## HM, ER, BI, JC, SP, 2014 and HM, BI, ER 2015 are DD missing decimals.
dat5<-dat1%>%
  # For records with coordinate information...
  filter(missing.coords!=1 & missing.location.rec!=1 & 
           # That are also either CT and RI sites HM, ER, BI, JC, or SP in 2014 OR
           # just CT sites HM, BI, ER in 2015...
           ((site.code %in% c("HM","ER","BI","JC","SP") & Year==2014) | (site.code %in% c("HM","BI","ER") & Year==2015)))%>%
           #add a decimal to the easting and northing values to turn into decimal degrees
  mutate(Long=as.numeric(paste0(substr(Easting,1,2),".",
                    substr(Easting,3,length(Easting)))),
         Lat=as.numeric(paste0(substr(Northing,1,2),".",
                                substr(Northing,3,length(Northing)))),
         #then remove the original values from the UTM coordinate columns
         Easting=NA,
         Northing=NA,
         #mark which edits were made
         batch_dec_addition=1)

dat1<-rbind(dat5,dat1[!(dat1$id%in%dat5$id),])



# B -3) Move DD data in easting/westing columns into long/lat columns
dat6<-dat1%>%
  # if Lat is missing and Easting is using values in Latitude range
  filter(abs(Easting)<46 & abs(Easting)>36 & is.na(Lat))%>%
      # fill in Lat from the Easting column
  mutate(Lat=abs(Easting))%>%
  dplyr::select(id,Lat)
  
dat7<-dat1%>%
  # if Lat is missing and and Northing is using values in Latitude range
  filter(abs(Northing)<46 & abs(Northing)>36 & is.na(Lat))%>%
     # fill in Lat from the NOrthing column
  mutate(Lat=abs(Northing))%>%
  dplyr::select(id,Lat)
  
dat8<-dat1%>%
  # if Long is missing and Easting is using values in Longitude range
  filter(abs(Easting)<79&abs(Easting)>64&is.na(Long))%>%
    # fill in Long from the Easting column
  mutate(Long=Easting)%>%
  dplyr::select(-Lat)
  
dat9<-dat1%>%
  # if Long is missing and Northing is using values in Longitude range
  filter(abs(Northing)<79&abs(Northing)>64&is.na(Long))%>%
    # fill in Long from the Northing column
  mutate(Long=Northing)%>%
  dplyr::select(-Lat)
  
dat10<-rbind(dat8,dat9)%>%
  left_join(rbind(dat6,dat7),by="id")%>%
  #remove lat long from easting northing columns
  mutate(Easting=NA,
         Northing=NA,
         #mark which edits were made
         batch_move_DD_to_LatLong = 1)

dat1<-rbind(dat10,dat1[!(dat1$id%in%dat10$id),])
      
# B -4) label the coordinate system and unit for all these nests as Decimal Degrees and all other nests as UTM
dat1<-dat1%>%
           mutate(Coordinate.System=case_when(
           (if_all(c(Lat,Long),~!is.na(.)) & missing.coords!=1) ~"Lat/Long(DD)",
           (if_all(c(Easting,Northing),~!is.na(.)) & missing.coords!=1) ~"UTM(m)",
           (if_all(c(Lat,Long),~!is.na(.)) & if_all(c(Easting,Northing),~!is.na(.))) ~"Lat/Long(DD), UTM(m)"))




## C) Fill in remaining missing UTM zones for CT. Longitude >= 72 DD is zone 18 <72 is zone 19

calc_zones <- dat1 %>% 
  filter(!is.na(Long)|Long=="NOT REC")%>%
  mutate(utm.zone=case_when(
    (is.na(utm.zone) & abs(as.numeric(Long))>=72) ~ "18T",
    (is.na(utm.zone) & abs(as.numeric(Long))<72) ~ "19T",
    !(is.na(utm.zone)) ~ utm.zone
  ))%>%
  distinct(site.code,.keep_all = T)%>%
  dplyr::select(site.code,utm.zone)

#Join site information to nest data and merge UTM zone info
dat1<-left_join(dat1,sites,by=c("site.code"))%>%
  left_join(calc_zones,by="site.code")%>%
  mutate(utm.zone=case_when(
    is.na(utm.zone) & !(is.na(utm.zone.y)) ~ utm.zone.y,
    is.na(utm.zone) & !(is.na(utm.zone.x)) ~ utm.zone.x,
    !(is.na(utm.zone)) ~ utm.zone))%>%
  #Waterford Beach CT site, WB, should be UTM zone 18T
  mutate(utm.zone=ifelse(site.code=="WB","18T",utm.zone))%>%
  dplyr::select(-c("utm.zone.x","utm.zone.y","coord.system"))
  

#Make sure all longitude values are negative
dat1<-dat1%>%
  mutate(Long=ifelse(Long!="NOT REC", -abs(as.numeric(Long)), Long))


## Plot Data
# -------------------------------------------

# get coordinate systems and convert coordinates to spatial data
utm18<- "+proj=utm +zone=18 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
utm19<- "+proj=utm +zone=19 +ellps=GRS80 +towgs84=0,0,0,0,0,0,0 +units=m +no_defs"
nad<-"+proj=longlat +ellps=GRS80 +datum=NAD83 +no_defs"

#convert to spatial points
plots_utm18 <- st_as_sf(filter(dat1,utm.zone=="18T"& Coordinate.System=="UTM(m)"), coords = c("Easting", "Northing"), crs = utm18)%>%
  st_transform(nad)

plots_utm19 <- st_as_sf(filter(dat1,utm.zone=="19T"& Coordinate.System=="UTM(m)"), coords = c("Easting", "Northing"), crs = utm19)%>%
  st_transform(nad)

plots_latlong <- st_as_sf(filter(dat1,Coordinate.System%in%c("Lat/Long(DD)","Lat/Long(DD), UTM(m)")), coords = c("Long", "Lat"), crs = nad)%>%
  #rename Lat Long to Northing Easting to combine data below
  rename("Long"="Easting","Lat"="Northing")
plots<-rbind(plots_utm18,plots_utm19,plots_latlong)%>%
  st_transform("EPSG:26918")



#admin boundaries
data(us_states)
ne<-filter(us_states,REGION=="Norteast")

#Marsh boundaries
marsh<-rast(paste0(dat_path,"UVVR/UVVR_annual_mean/uvvr_mean_utm18_2.tif"))

#plot nest sites
tm_shape(ne) + tm_borders() +
tm_shape(plots) + tm_dots()

#Mark as error if plotting outside marsh layer (UVVR)
plots<-terra::extract(marsh,vect(plots),bind=T)%>%
  sf::st_as_sf()%>%
  mutate(coord.typo=ifelse(
    uvvr_mean_utm18_2=="NaN",1,0
  ))%>%
  dplyr::select(-uvvr_mean_utm18_2)


# add error flag edits in Arc (removed error flags around nest points on marsh border and added to nests plotting at the wrong site) 
error_edits<-st_read(paste0(dat_path,"Nest Locations/nest_locations_11_10_22.shp"))%>%
  st_drop_geometry()%>%
  dplyr::select(id,crd_typ)
plots<-plots%>%
  left_join(error_edits,by="id")%>%
  mutate(coord.typo=ifelse(!(site.code%in%c("AT","OC","MW") & Year==2014),crd_typ,coord.typo))%>%
  dplyr::select(-crd_typ)




#outputs

#nest points shp
output_shp<-dplyr::select(plots,id,coord.typo)%>%
  left_join(dplyr::select(dat1,-c("coord.typo","Lat2","Long2")),by="id")%>%
  distinct(id,.keep_all = T)

st_write(output_shp,
         paste0(dat_path,"Nest Locations/nest_locations_12_9_22.shp"), delete_layer =T)
st_write(output_shp,
         paste0(dat_path,"Nest Locations/nest_locations_12_9_22.kml"), delete_layer =T)

#nest coordinate info csv
output_csv<-dplyr::select(plots,id,coord.typo)%>%
  st_drop_geometry()%>%
  right_join(dplyr::select(dat1,-c("coord.typo")),by="id")%>%
  distinct(id,.keep_all = T)%>%
  mutate(coord.typo=ifelse(is.na(coord.typo),0,coord.typo))%>%
  ## Add edit note information
  mutate(missing.location.rec2=ifelse(missing.location.rec==1,"Nest fate record is missing nest location record. ",""),
         missing.site.info2=ifelse(missing.site.info==1,"Missing site information. ",""),
         missing.coords2=ifelse(missing.coords==1,"Missing coordinates in nest location record. ",""),
         batch_DecMin_DD_reversed2=ifelse(batch_DecMin_DD_reversed==1,"Batch conversion for NJ sites (OC, AT, MW) in 2015: Degree Decimal Minutes to Decimal Degrees and reversed Lat and Long column values. ",""),
         replace_dat2=ifelse(replace_dat==1,"Batch conversion for NJ sites (OC, AT, MW) in 2014: Replaced coordinates with Sam R's original data. ",""),
         batch_dec_addition2=ifelse(batch_dec_addition==1,"Batch conversion for CT and RI sites (HM, BI, ER, JC, SP) in 2014 and just CT (HM, BI, ER) in 2015: Added missing decimal to Decimal Degrees in Easting/Northin cols. ",""),
         coord_shift2=ifelse(coord_shift==1,paste0("Database coordinates are shifted N. East. Added average difference from Sam R's original SALS and SESP nest records to original database coordinates (", round(Lat2,5), " N, ",round(Long2,5)," W). "),""),
         batch_move_DD_to_LatLong2 = ifelse(batch_move_DD_to_LatLong == 1, "Moved decimal degrees in the Easting Northing columns to Lat Long Columns. ", ""),
         coord.typo2=ifelse(coord.typo==1,"Nest locations still plot outside site area. ",""),
         Notes=paste0(missing.location.rec2,missing.site.info2,missing.coords2,batch_DecMin_DD_reversed2,replace_dat2,batch_dec_addition2, coord_shift2, coord.typo2, batch_move_DD_to_LatLong2),
         Notes=ifelse(Notes=="",Notes,paste0(Notes,"12/9/22 EF."))
  )%>%
  dplyr::select(-c("missing.location.rec2","missing.site.info2","missing.coords2","batch_DecMin_DD_reversed2","replace_dat2","batch_dec_addition2","coord.typo2", "coord_shift2","batch_move_DD_to_LatLong2","Lat2","Long2"))
write.csv(output_csv,paste0(dat_path,"new_nest_coords_12_9_22.csv"),row.names = F)

#Site table info
output_site<-output_csv%>%
  dplyr::select(site.code,Site,State,utm.zone)%>%
  distinct(Site,.keep_all = T)%>%
  right_join(sites,by=c("site.code","Site","State"))%>%
  mutate(utm.zone=case_when(
         is.na(utm.zone.x) ~ utm.zone.y,
         !(is.na(utm.zone.x))~utm.zone.x))%>%
  dplyr::select(-c("utm.zone.x","utm.zone.y"))
write.csv(output_site,paste0(dat_path,"compiled_site_table_11_10_22.csv"),row.names = F)

# error tally
t<-summarise(output_csv,
             missing.location.rec=sum(missing.location.rec),
             missing.site.info=sum(missing.site.info),
             missing.coords=sum(missing.coords),
             batch_DecMin_DD_reversed=sum(batch_DecMin_DD_reversed),
             replace_dat=sum(replace_dat),
             batch_dec_addition=sum(batch_dec_addition),
             no_replacement=sum(no_replacement),
             batch_move_DD_to_LatLong = sum(batch_move_DD_to_LatLong ),
             coord.typo=sum(coord.typo,na.rm=T))

